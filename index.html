<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI Voice Companion</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      background-color: #1a1a1a;
      color: white;
      font-family: 'Segoe UI', sans-serif;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      overflow: hidden;
    }

    #character-container {
        position: relative;
        width: 100%;
        max-width: 600px;
        height: 80vh;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    #character {
        max-width: 100%;
        max-height: 100%;
        object-fit: contain;
        cursor: pointer;
        filter: drop-shadow(0 0 15px #ffffff22);
        transition: filter 0.3s ease;
    }

    #character:hover {
        filter: drop-shadow(0 0 25px #ffffff44);
    }

    /* Start Screen Overlay */
    #start-screen {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        background: rgba(0,0,0,0.85);
        display: flex;
        justify-content: center;
        align-items: center;
        z-index: 9999;
        cursor: pointer;
        flex-direction: column;
    }
    
    #start-btn {
        padding: 20px 40px;
        font-size: 24px;
        background: #007bff;
        color: white;
        border: none;
        border-radius: 50px;
        cursor: pointer;
        transition: transform 0.2s;
    }
    
    #start-btn:hover { transform: scale(1.05); background: #0056b3; }

    .controls {
        position: absolute;
        top: 20px;
        right: 20px;
        z-index: 100;
        display: flex;
        gap: 10px;
    }

    select {
        background: #333;
        color: white;
        border: 1px solid #555;
        padding: 8px 15px;
        border-radius: 5px;
        font-family: inherit;
        cursor: pointer;
        outline: none;
        font-size: 14px;
    }

    select:hover {
        background: #444;
    }

    .status-text {
        position: absolute;
        bottom: 30px;
        font-size: 18px;
        color: #aaa;
        font-weight: 300;
        font-style: italic;
        text-align: center;
        background: rgba(0,0,0,0.5);
        padding: 5px 15px;
        border-radius: 20px;
        max-width: 80%;
    }
    
    /* Processing State (Non-clickable) */
    .processing {
        cursor: wait !important;
        opacity: 0.8;
    }
  </style>
</head>
<body>

  <!-- Start Screen -->
  <div id="start-screen">
      <button id="start-btn">Click to Start</button>
      <p style="margin-top:10px; color:#aaa;">Enable Audio & Microphone</p>
  </div>

  <!-- Controls -->
  <div class="controls">
      <select id="char-select">
          <option value="emma">Emma</option>
          <option value="erza_sen">Erza Scarlet</option>
          <option value="nefer">Neferpitou</option>
          <option value="rias">Rias Gremory</option>
      </select>
  </div>
  
  <div id="character-container">
      <img id="character" src="" alt="AI Character">
  </div>
  
  <div id="status" class="status-text">Waiting...</div>

  <audio id="beep" src="https://www.soundjay.com/button/sounds/button-3.mp3" preload="auto"></audio>
  <audio id="welcome-audio" src="asstes/welcome.wav" preload="auto"></audio>

  <script>
    // --- DOM Elements ---
    const charImg = document.getElementById('character');
    const statusText = document.getElementById('status');
    const charSelect = document.getElementById('char-select');
    const beepAudio = document.getElementById('beep');
    const welcomeAudio = document.getElementById('welcome-audio');
    const startScreen = document.getElementById('start-screen');

    // --- Configuration ---
    const CONFIG = {
        framerate: 120, 
        padLength: 4,  
        filePrefix: 'frame_',
        fileExt: '.jpg'
    };

    const CHARACTERS = {
        emma: {
            idle:    { folder: 'emma_idle', frameCount: 40 },
            talking: { folder: 'emma_talking', frameCount: 40 },
            waving:  { folder: 'emma_waving', frameCount: 40 }
        },
        erza_sen: {
            idle:    { folder: 'erza_sen_teasing', frameCount: 40 }, 
            talking: { folder: 'erza_sen_talking', frameCount: 40 },
            waving:  { folder: 'erza_sen_waving', frameCount: 40 },
            teasing: { folder: 'erza_sen_teasing', frameCount: 40 }
        },
        nefer: {
            idle:    { folder: 'nefer_talking', frameCount: 40 },
            talking: { folder: 'nefer_talking', frameCount: 40 },
            waving:  { folder: 'nefer_talking', frameCount: 40 } 
        },
        rias: {
            idle:    { folder: 'rias_talking', frameCount: 40 },
            talking: { folder: 'rias_talking', frameCount: 40 },
            waving:  { folder: 'rias_summon', frameCount: 40 }
        }
    };

    // --- State Variables ---
    let currentCharField = 'emma';
    let currentState = 'idle'; 
    let animationInterval = null;
    let frameIndex = 1;
    let frameDirection = 1; 
    let isRecording = false;
    let isProcessing = false; // New lock variable
    let mediaRecorder;
    let audioChunks = [];

    // --- Animation Logic ---

    function padNumber(num, size) {
        let s = "000000000" + num;
        return s.substr(s.length - size);
    }

    function getFramePath(charName, state, index) {
        const charData = CHARACTERS[charName];
        let stateObj = charData[state] || charData['idle'] || charData['talking'];
        const folder = stateObj.folder;
        const filename = `${CONFIG.filePrefix}${padNumber(index, CONFIG.padLength)}${CONFIG.fileExt}`;
        return `${folder}/${filename}`;
    }

    function startAnimation() {
        if (animationInterval) clearInterval(animationInterval);

        const charData = CHARACTERS[currentCharField];
        let stateObj = charData[currentState] || charData['idle'];
        let maxFrames = stateObj.frameCount || 40; 

        animationInterval = setInterval(() => {
            frameIndex += frameDirection;

            if (frameIndex >= maxFrames) {
                frameIndex = maxFrames;
                frameDirection = -1; 
            } else if (frameIndex <= 1) {
                frameIndex = 1;
                frameDirection = 1; 
            }

            const path = getFramePath(currentCharField, currentState, frameIndex);
            
            const img = new Image();
            img.src = path;
            
            img.onload = () => { charImg.src = path; };
            
            // Auto-stop on missing frames
            img.onerror = () => {
                if (frameDirection === 1) {
                    stateObj.frameCount = frameIndex - 1;
                    maxFrames = frameIndex - 1;
                    frameDirection = -1;
                    frameIndex = Math.max(1, frameIndex - 2); 
                }
            };

        }, CONFIG.framerate);
    }

    function setState(newState) {
        if (currentState === newState) return;
        currentState = newState;
        frameIndex = 1; 
        frameDirection = 1;
        const path = getFramePath(currentCharField, currentState, 1);
        charImg.src = path;
        startAnimation();
    }

    // --- Character Switching & Welcome ---
    
    function triggerWelcomeSequence(charName) {
        currentCharField = charName;
        const displayName = charSelect.options[charSelect.selectedIndex].text;
        statusText.textContent = `Hello, I'm ${displayName}`;
        setState('waving');

        welcomeAudio.pause();
        welcomeAudio.currentTime = 0;
        welcomeAudio.play().catch(e => console.log("Waiting for interaction"));

        welcomeAudio.onended = () => {
            setState('idle');
            statusText.textContent = "Click the character to speak";
        };
    }

    charSelect.addEventListener('change', (e) => {
        if (isProcessing) return; // Prevent switching while thinking
        triggerWelcomeSequence(e.target.value);
    });

    // --- Start Screen Logic ---
    startScreen.addEventListener('click', () => {
        startScreen.style.display = 'none';
        triggerWelcomeSequence('emma');
    });

    // --- Recording & AI Logic ---

    function setProcessingState(active) {
        isProcessing = active;
        if (active) {
            charImg.classList.add('processing');
        } else {
            charImg.classList.remove('processing');
        }
    }

    function sendToN8n(base64Audio) {
        statusText.textContent = "Thinking... (Please wait)";
        setState('idle'); 
        setProcessingState(true); // LOCK INTERFACE

        const n8nWebhookUrl = 'https://n8n.srv1120095.hstgr.cloud/webhook-test/ai-waifu-voice-input';

        fetch(n8nWebhookUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                audioData: base64Audio,
                fileName: `recording-${new Date().toISOString()}.webm`
            }),
        })
        .then(response => {
            // Detailed Error Reporting
            if (!response.ok) {
                if (response.status === 504) throw new Error("Server Timeout (AI took too long)");
                if (response.status === 502) throw new Error("Bad Gateway (Server overload)");
                throw new Error(`Server Error: ${response.status}`);
            }
            
            // Warn if JSON returned instead of Audio
            const contentType = response.headers.get("content-type");
            if (contentType && contentType.includes("application/json")) {
                console.warn("Received JSON, expected Audio. Checking for error message...");
                // Note: We don't throw immediately, we try to parse it to see the error
            }

            return response.blob();
        })
        .then(audioBlob => {
            // Check for empty response
            if (audioBlob.size < 100) throw new Error("Empty response from AI");

            // Check if it's actually a JSON error hidden in a blob
            if (audioBlob.type.includes('json')) {
                throw new Error("AI returned an error message (JSON)");
            }

            const audioURL = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioURL);

            audio.addEventListener('playing', () => {
              setState('talking');
              statusText.textContent = "Responding...";
            });

            audio.addEventListener('ended', () => {
              setState('idle');
              statusText.textContent = "Click to speak again";
              setProcessingState(false); // UNLOCK
            });
            
            audio.addEventListener('error', (e) => {
                throw new Error("Audio format not supported");
            });

            audio.play();
        })
        .catch(err => {
            console.error(err);
            statusText.textContent = `Error: ${err.message}`;
            setState('idle');
            setProcessingState(false); // UNLOCK on error
        });
    }

    async function toggleRecording() {
        if (isProcessing) return; // Prevent interaction if busy

        if (isRecording) {
            stopRecording();
        } else {
            startRecording();
        }
    }

    async function startRecording() {
      try {
        welcomeAudio.pause();
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        isRecording = true;
        audioChunks = [];
        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.addEventListener("dataavailable", event => {
          audioChunks.push(event.data);
        });

        mediaRecorder.addEventListener("stop", () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const reader = new FileReader();
          reader.readAsDataURL(audioBlob);
          reader.onloadend = () => {
            sendToN8n(reader.result);
          };
        });

        beepAudio.play();
        mediaRecorder.start();
        
        charImg.style.filter = "drop-shadow(0 0 15px #ff0000aa)";
        statusText.textContent = "Listening... (Click to stop)";
        setState('idle'); 

      } catch (error) {
        console.error("Mic Error:", error);
        statusText.textContent = "Microphone access denied.";
        isRecording = false;
      }
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
        isRecording = false;
        charImg.style.filter = ""; 
      }
    }

    // --- Start ---
    charImg.addEventListener('click', toggleRecording);
    
    // Note: window.onload is handled by the Start Screen now
  </script>
</body>
</html>
