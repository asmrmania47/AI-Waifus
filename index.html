<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI Voice Companion</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      background-color: #1a1a1a;
      color: white;
      font-family: 'Segoe UI', sans-serif;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      overflow: hidden;
    }

    #character-container {
        position: relative;
        width: 100%;
        max-width: 600px;
        height: 80vh;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    #character {
        max-width: 100%;
        max-height: 100%;
        object-fit: contain;
        cursor: pointer;
        filter: drop-shadow(0 0 15px #ffffff22);
        transition: filter 0.3s ease;
    }

    #character:hover {
        filter: drop-shadow(0 0 25px #ffffff44);
    }

    .controls {
        position: absolute;
        top: 20px;
        right: 20px;
        z-index: 100;
        display: flex;
        gap: 10px;
    }

    select {
        background: #333;
        color: white;
        border: 1px solid #555;
        padding: 8px 15px;
        border-radius: 5px;
        font-family: inherit;
        cursor: pointer;
        outline: none;
        font-size: 14px;
    }

    select:hover {
        background: #444;
    }

    .status-text {
        position: absolute;
        bottom: 30px;
        font-size: 18px;
        color: #aaa;
        font-weight: 300;
        font-style: italic;
        text-align: center;
        background: rgba(0,0,0,0.5);
        padding: 5px 15px;
        border-radius: 20px;
    }
  </style>
</head>
<body>

  <!-- Controls -->
  <div class="controls">
      <select id="char-select">
          <option value="emma">Emma</option>
          <option value="erza_sen">Erza Scarlet</option>
          <option value="nefer">Neferpitou</option>
          <option value="rias">Rias Gremory</option>
      </select>
  </div>
  
  <div id="character-container">
      <img id="character" src="" alt="AI Character">
  </div>
  
  <div id="status" class="status-text">Initializing...</div>

  <!-- Audio Elements -->
  <audio id="beep" src="https://www.soundjay.com/button/sounds/button-3.mp3" preload="auto"></audio>
  <!-- TYPO FIXED: asstes -> assets -->
  <audio id="welcome-audio" src="asstes/welcome.wav" preload="auto"></audio>

  <script>
    // --- DOM Elements ---
    const charImg = document.getElementById('character');
    const statusText = document.getElementById('status');
    const charSelect = document.getElementById('char-select');
    const beepAudio = document.getElementById('beep');
    const welcomeAudio = document.getElementById('welcome-audio');

    // --- Configuration ---
    const CONFIG = {
        framerate: 100, 
        padLength: 4,  
        filePrefix: 'frame_',
        fileExt: '.jpg'
    };

    const CHARACTERS = {
        emma: {
            idle:    { folder: 'emma_idle', frameCount: 75 },
            talking: { folder: 'emma_talking', frameCount: 75 },
            waving:  { folder: 'emma_waving', frameCount: 75 }
        },
        erza_sen: {
            idle:    { folder: 'erza_sen_teasing', frameCount: 60 }, 
            talking: { folder: 'erza_sen_talking', frameCount: 60 },
            waving:  { folder: 'erza_sen_waving', frameCount: 60 },
            teasing: { folder: 'erza_sen_teasing', frameCount: 60 }
        },
        nefer: {
            idle:    { folder: 'nefer_talking', frameCount: 50 },
            talking: { folder: 'nefer_talking', frameCount: 50 },
            waving:  { folder: 'nefer_talking', frameCount: 50 } 
        },
        rias: {
            idle:    { folder: 'rias_talking', frameCount: 60 },
            talking: { folder: 'rias_talking', frameCount: 60 },
            waving:  { folder: 'rias_summon', frameCount: 60 }
        }
    };

    // --- State Variables ---
    let currentCharField = 'emma';
    let currentState = 'idle'; 
    let animationInterval = null;
    let frameIndex = 1;
    let frameDirection = 1; 
    let isRecording = false;
    let mediaRecorder;
    let audioChunks = [];

    // --- Animation Logic ---

    function padNumber(num, size) {
        let s = "000000000" + num;
        return s.substr(s.length - size);
    }

    function getFramePath(charName, state, index) {
        const charData = CHARACTERS[charName];
        
        let stateObj = charData[state];
        
        if (!stateObj) {
            stateObj = charData['idle'];
            if (!stateObj) stateObj = charData['talking'];
        }

        const folder = stateObj.folder;
        const filename = `${CONFIG.filePrefix}${padNumber(index, CONFIG.padLength)}${CONFIG.fileExt}`;
        return `${folder}/${filename}`;
    }

    function startAnimation() {
        if (animationInterval) clearInterval(animationInterval);

        const charData = CHARACTERS[currentCharField];
        let stateObj = charData[currentState] || charData['idle'];
        // Dynamic frame limit to handle different folder sizes
        let maxFrames = stateObj.frameCount || 50; 

        animationInterval = setInterval(() => {
            frameIndex += frameDirection;

            // Ping-Pong Logic
            if (frameIndex >= maxFrames) {
                frameIndex = maxFrames;
                frameDirection = -1; 
            } else if (frameIndex <= 1) {
                frameIndex = 1;
                frameDirection = 1; 
            }

            const path = getFramePath(currentCharField, currentState, frameIndex);
            
            const img = new Image();
            img.src = path;
            
            img.onload = () => { 
                charImg.src = path; 
            };
            
            // AUTO-STOP: If frame doesn't exist, turn around immediately
            img.onerror = () => {
                if (frameDirection === 1) {
                    // Update the limit for this state temporarily to prevent future 404s
                    stateObj.frameCount = frameIndex - 1;
                    maxFrames = frameIndex - 1;
                    
                    frameDirection = -1;
                    frameIndex = Math.max(1, frameIndex - 2); 
                }
            };

        }, CONFIG.framerate);
    }

    function setState(newState) {
        if (currentState === newState) return;
        
        currentState = newState;
        frameIndex = 1; 
        frameDirection = 1;
        
        const path = getFramePath(currentCharField, currentState, 1);
        charImg.src = path;
        
        startAnimation();
    }

    // --- Character Switching & Welcome ---
    
    function triggerWelcomeSequence(charName) {
        currentCharField = charName;
        
        const displayName = charSelect.options[charSelect.selectedIndex].text;
        statusText.textContent = `Hello, I'm ${displayName}`;
        
        setState('waving');

        welcomeAudio.pause();
        welcomeAudio.currentTime = 0;
        
        welcomeAudio.play().catch(e => {
            console.log("Autoplay blocked until user interaction.");
        });

        welcomeAudio.onended = () => {
            setState('idle');
            statusText.textContent = "Click the character to speak";
        };
    }

    charSelect.addEventListener('change', (e) => {
        triggerWelcomeSequence(e.target.value);
    });

    // --- Recording & AI Logic ---

    function sendToN8n(base64Audio) {
        statusText.textContent = "Thinking...";
        setState('idle'); // Ensure idle while thinking

        const n8nWebhookUrl = 'https://n8n.srv1120095.hstgr.cloud/webhook-test/ai-waifu-voice-input';

        fetch(n8nWebhookUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                audioData: base64Audio,
                fileName: `recording-${new Date().toISOString()}.webm`
            }),
        })
        .then(response => {
            // FIX 1: Check content type. If n8n sends JSON, it's an error, not audio.
            const contentType = response.headers.get("content-type");
            if (contentType && contentType.indexOf("application/json") !== -1) {
                console.warn("Server returned JSON instead of audio.");
                throw new Error("AI returned text/error, not audio.");
            }
            if (!response.ok) throw new Error(`Server error: ${response.status}`);
            return response.blob();
        })
        .then(audioBlob => {
            // FIX 2: Check if blob is too small (empty response)
            if (audioBlob.size < 100) throw new Error("Audio response was empty.");

            const audioURL = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioURL);

            // FIX 3: Use 'playing' instead of 'play'. 
            // 'playing' fires when sound actually starts emitting.
            audio.addEventListener('playing', () => {
              setState('talking');
              statusText.textContent = "Responding...";
            });

            audio.addEventListener('ended', () => {
              setState('idle');
              statusText.textContent = "Click the character to speak";
            });
            
            audio.addEventListener('error', (e) => {
                console.error("Audio failed to play", e);
                statusText.textContent = "Error playing audio.";
                setState('idle');
            });

            audio.play();
        })
        .catch(err => {
            console.error(err);
            statusText.textContent = "Error: " + err.message;
            setState('idle');
        });
    }

    async function toggleRecording() {
        if (isRecording) {
            stopRecording();
        } else {
            startRecording();
        }
    }

    async function startRecording() {
      try {
        welcomeAudio.pause();
        
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        isRecording = true;
        audioChunks = [];
        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.addEventListener("dataavailable", event => {
          audioChunks.push(event.data);
        });

        mediaRecorder.addEventListener("stop", () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const reader = new FileReader();
          reader.readAsDataURL(audioBlob);
          reader.onloadend = () => {
            sendToN8n(reader.result);
          };
        });

        beepAudio.play();
        mediaRecorder.start();
        
        charImg.style.filter = "drop-shadow(0 0 15px #ff0000aa)";
        statusText.textContent = "Listening...";
        setState('idle'); 

      } catch (error) {
        console.error("Mic Error:", error);
        statusText.textContent = "Microphone access denied.";
        isRecording = false;
      }
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
        isRecording = false;
        charImg.style.filter = ""; 
      }
    }

    // --- Start ---
    charImg.addEventListener('click', toggleRecording);

    window.onload = () => {
        triggerWelcomeSequence('emma');
    };

  </script>
</body>
</html>
