<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI Voice Companion</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      background-color: #1a1a1a; /* Darker grey for better contrast */
      color: white;
      font-family: 'Segoe UI', sans-serif;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      overflow: hidden;
    }

    #character {
        width: 280px;
        height: 280px;
        cursor: pointer;
        /* Optional: Add a subtle glow to the character */
        filter: drop-shadow(0 0 15px #ffffff33);
        transition: filter 0.3s ease;
    }

    #character:hover {
        filter: drop-shadow(0 0 25px #ffffff55);
    }

    .status-text {
      margin-top: 20px;
      font-size: 18px;
      color: #aaa;
      font-weight: 300;
      font-style: italic;
      min-height: 27px; /* Reserve space to prevent layout shifts */
    }
  </style>
</head>
<body>
  
  <img id="character" src="assets/hakoz/closedmouth.png" alt="Click to speak with AI" title="Click to speak with AI">
  
  <div id="status" class="status-text">Click the character to speak</div>

  <audio id="beep" src="https://www.soundjay.com/button/sounds/button-3.mp3" preload="auto"></audio>

  <script>
    const character = document.getElementById('character');
    const statusText = document.getElementById('status');
    const beep = document.getElementById('beep');

    // --- Animation State ---
    const characterStates = {
        idle: 'assets/hakoz/closedmouth.png',
        blink: 'assets/hakoz/closedeyes.png',
        listening: 'assets/hakoz/thinking.png',
        speaking: [
            'assets/hakoz/openmouth.png',
            'assets/hakoz/closedmouth.png'
        ]
    };
    
    // Preload images for smooth animation
    function preloadImages() {
        const imagesToLoad = [
            characterStates.idle, 
            characterStates.blink, 
            characterStates.listening, 
            ...characterStates.speaking
        ];
        imagesToLoad.forEach(src => {
            const img = new Image();
            img.src = src;
        });
    }
    preloadImages();

    let idleAnimationInterval;
    let speakingAnimationInterval;

    // --- Animation Functions ---
    function startIdleAnimation() {
        stopAllAnimations();
        character.src = characterStates.idle;
        // Blink every 4 seconds
        idleAnimationInterval = setInterval(() => {
            character.src = characterStates.blink;
            setTimeout(() => {
                // Check if we are still in idle state before switching back
                if (character.src.includes('closedeyes')) {
                    character.src = characterStates.idle;
                }
            }, 200); // Blink duration
        }, 4000);
    }

    function startSpeakingAnimation() {
        stopAllAnimations();
        let frame = 0;
        // Cycle through speaking frames
        speakingAnimationInterval = setInterval(() => {
            character.src = characterStates.speaking[frame];
            frame = (frame + 1) % characterStates.speaking.length;
        }, 200); // Speed of mouth movement
    }

    function stopAllAnimations() {
        clearInterval(idleAnimationInterval);
        clearInterval(speakingAnimationInterval);
    }
    
    // --- Core Logic ---
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;

    function sendToN8n(base64Audio) {
        statusText.textContent = "Processing...";
        // The image remains in the 'listening' state while processing
        const n8nWebhookUrl = 'https://n8n.srv1120095.hstgr.cloud/webhook/ai-voice-input';

        fetch(n8nWebhookUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                audioData: base64Audio,
                fileName: `recording-${new Date().toISOString()}.webm`
            }),
        })
        .then(response => {
            if (!response.ok) throw new Error(`Server response was not ok: ${response.status}`);
            return response.blob();
        })
        .then(audioBlob => {
            const audioURL = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioURL);

            audio.onplay = () => {
              startSpeakingAnimation();
              statusText.textContent = "Responding...";
            };

            audio.onended = () => {
              startIdleAnimation();
              statusText.textContent = "Click the character to speak";
            };

            audio.play();
        })
        .catch(err => {
            console.error("Error communicating with n8n:", err);
            statusText.textContent = "Error communicating with AI.";
            startIdleAnimation(); // Revert to idle on error
        });
    }

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        isRecording = true;
        audioChunks = [];
        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.addEventListener("dataavailable", event => {
          audioChunks.push(event.data);
        });

        mediaRecorder.addEventListener("stop", () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const reader = new FileReader();
          reader.readAsDataURL(audioBlob);
          reader.onloadend = () => {
            const base64String = reader.result;
            sendToN8n(base64String);
          };
        });

        beep.play();
        mediaRecorder.start();
        
        stopAllAnimations();
        character.src = characterStates.listening;
        statusText.textContent = "Listening...";
      } catch (error) {
        console.error("Error accessing microphone:", error);
        statusText.textContent = "Error: Microphone permission denied.";
        isRecording = false;
      }
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
        isRecording = false;
        // Status will be updated to "Processing..." in the sendToN8n function
      }
    }

    // Main click handler for the character
    character.addEventListener('click', () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    });

    // Start in idle state when the page loads
    window.onload = startIdleAnimation;

  </script>
</body>
</html>```
